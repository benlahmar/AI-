{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55a8ca8",
   "metadata": {
    "id": "intro"
   },
   "source": [
    "# üéì Travaux Pratiques : DCGAN (Deep Convolutional GAN)\n",
    "\n",
    "**Auteur :**Benlahmar Habib\n",
    "\n",
    "\n",
    "## Objectifs P√©dagogiques\n",
    "\n",
    "1.  **Architecture Convolutive :** Comprendre comment les couches `Conv2d` et `ConvTranspose2d` am√©liorent la qualit√© des images g√©n√©r√©es par rapport au MLP-GAN.\n",
    "2.  **Stabilit√© de l'Entra√Ænement :** Assimiler le r√¥le critique de la **Normalisation par Batch (Batch Normalization)** et l'ajustement de la normalisation des donn√©es √† $[-1, 1]$.\n",
    "3.  **Impl√©mentation DCGAN :** Mettre en ≈ìuvre le mod√®le DCGAN original sur Fashion-MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06db82ba",
   "metadata": {
    "id": "concept_dcgan"
   },
   "source": [
    "--- \n",
    "\n",
    "## I. Fondements du DCGAN\n",
    "\n",
    "Le DCGAN est l'un des premiers mod√®les √† √©tablir des lignes directrices claires pour construire des GANs stables et performants avec des r√©seaux profonds et convolutifs (Radford et al., 2016).\n",
    "\n",
    "### 1.1. Lignes Directrices Architecturales\n",
    "\n",
    "1.  **Remplacer les couches de *Pooling*** : Utiliser des convolutions √† **pas (stride)** fractionn√© (`ConvTranspose2d`) dans $G$ et des convolutions √† pas dans $D$ pour les op√©rations d'√©chantillonnage (upsampling/downsampling).\n",
    "2.  **Normalisation par Batch (BN) :** Appliquer `nn.BatchNorm2d` au G√©n√©rateur et au Discriminateur pour stabiliser les activations et pr√©venir le gradient vanishing (sauf la premi√®re couche de $D$ et la couche de sortie de $G$).\n",
    "3.  **Activations :** Utiliser **ReLU** dans $G$ (sauf la sortie) et **LeakyReLU** dans $D$ pour permettre aux gradients de circuler sans probl√®me.\n",
    "4.  **Sortie :** Utiliser **`nn.Tanh()`** dans la couche de sortie de $G$ pour forcer les pixels dans l'intervalle $[-1, 1]$.\n",
    "\n",
    "### Question  (Q1.1)\n",
    "\n",
    "Pourquoi la *Normalisation par Batch (BatchNorm)* est-elle particuli√®rement b√©n√©fique dans l'entra√Ænement du Discriminateur, qui est d√©j√† un classifieur binaire standard ? (Indice : Pensez √† l'√©chelle des activations et √† la lutte entre $G$ et $D$).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8361e1",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## II. Configuration et Pr√©paration des Donn√©es √† $[-1, 1]$\n",
    "\n",
    "**ATTENTION :** En raison de l'activation `nn.Tanh()` dans le G√©n√©rateur, nous devons normaliser les donn√©es d'entr√©e de Fashion-MNIST dans l'intervalle **$[-1, 1]$** (au lieu de $[0, 1]$). La formule utilis√©e est $\\mathbf{x}' = (\\mathbf{x} - 0.5) \\times 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd67fe",
   "metadata": {
    "id": "imports_dcgan"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Ex√©cution sur {device}\")\n",
    "\n",
    "# Hyperparam√®tres\n",
    "latent_dim = 100\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "lr = 0.0002\n",
    "\n",
    "# NORMALISATION CRITIQUE : [0, 1] -> [-1, 1]\n",
    "transform_dcgan = transforms.Compose([\n",
    "    transforms.ToTensor(), # Normalise en [0, 1]\n",
    "    transforms.Normalize((0.5,), (0.5,)) # (x - 0.5) / 0.5 -> [-1, 1]\n",
    "])\n",
    "\n",
    "# Chargement des donn√©es\n",
    "train_dataset = datasets.FashionMNIST(root='./data/FashionMNIST', train=True, download=True, transform=transform_dcgan)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialisation des poids (selon les recommandations DCGAN)\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b683409c",
   "metadata": {
    "id": "q2"
   },
   "source": [
    "### Question  (Q2.1)\n",
    "\n",
    "Expliquez pourquoi le G√©n√©rateur doit utiliser l'activation `Tanh` en sortie, et comment cela contraint le pr√©traitement des donn√©es √† une normalisation dans l'intervalle $[-1, 1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c6761",
   "metadata": {
    "id": "arch_dcgan"
   },
   "source": [
    "--- \n",
    "\n",
    "## III. Architecture du DCGAN (28x28)\n",
    "\n",
    "Nous ajustons l'architecture DCGAN pour la taille $28 \\times 28$ de Fashion-MNIST. Les couches `ConvTranspose2d` et `Conv2d` sont l'analogue de *l'upsampling* et du *downsampling*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3071aaca",
   "metadata": {
    "id": "g_dcgan"
   },
   "source": [
    "### 3.1. Le G√©n√©rateur ($G_{\\text{DCGAN}}$)\n",
    "\n",
    "Input : $\\mathbf{z}$ (100 dimensions). Output : $1 \\times 28 \\times 28$. Les couches `ConvTranspose2d` augmentent la r√©solution spatiale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b60018",
   "metadata": {
    "id": "generator_dcgan"
   },
   "outputs": [],
   "source": [
    "# Nombre de feature maps (canaux)\n",
    "ngf = 64 # Nombre de 'Generative Feature maps'\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Projection initiale du bruit z (100) en volume spatial (ngf*4 x 4 x 4)\n",
    "            nn.ConvTranspose2d(latent_dim, ngf * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # √âtat : (ngf*4) x 4 x 4\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # √âtat : (ngf*2) x 8 x 8 (r√©solution non standard 28x28, ajustement n√©cessaire)\n",
    "            \n",
    "            # Pour atteindre 28x28 √† partir de 8x8, nous avons besoin d'un upsampling progressif\n",
    "            # Simplification pour 28x28 (en ajustant le padding/kernel pour le dernier bloc)\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # √âtat : (ngf) x 16 x 16\n",
    "\n",
    "            # Derni√®re couche pour atteindre 28x28 (kernel 4, stride 2, padding 3)\n",
    "            nn.ConvTranspose2d(ngf, 1, 4, 2, 3, bias=False), # Output: 28 x 28 x 1\n",
    "            nn.Tanh() # Sortie normalis√©e entre [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        # z doit √™tre transform√© en volume 4D pour les ConvTranspose2d\n",
    "        return self.main(z.view(-1, latent_dim, 1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b9255d",
   "metadata": {
    "id": "d_dcgan"
   },
   "source": [
    "### 3.2. Le Discriminateur ($D_{\\text{DCGAN}}$)\n",
    "\n",
    "Input : $1 \\times 28 \\times 28$. Output : Logit scalaire. Les couches `Conv2d` r√©duisent la r√©solution spatiale. **NOTE** : Pas de BN sur la premi√®re couche de $D$ (selon les recommandations DCGAN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12d69b",
   "metadata": {
    "id": "discriminator_dcgan"
   },
   "outputs": [],
   "source": [
    "ndf = 64 # Nombre de 'Discriminator Feature maps'\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Couche d'entr√©e (pas de BN) : 1 x 28 x 28 -> ndf x 14 x 14\n",
    "            nn.Conv2d(1, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # ndf x 14 x 14 -> ndf*2 x 7 x 7\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # ndf*2 x 7 x 7 -> ndf*4 x 4 x 4\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # Couche de sortie : ndf*4 x 4 x 4 -> 1 (logit)\n",
    "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False), \n",
    "            # La sortie n'est pas activ√©e (pas de Sigmoid), elle est en format logit\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Le Discriminateur renvoie un logit (scalaire) apr√®s un squeeze()\n",
    "        return self.main(input).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc413a59",
   "metadata": {
    "id": "q3"
   },
   "source": [
    "### Question  (Q3.1)\n",
    "\n",
    "Observez l'architecture du G√©n√©rateur. Quel est le r√¥le de la couche `ConvTranspose2d` dans ce r√©seau ? Comment le fait d'utiliser des convolutions, plut√¥t que des couches lin√©aires, permet-il de garantir une meilleure **coh√©rence spatiale** (c'est-√†-dire des formes plus r√©alistes) dans les images g√©n√©r√©es ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649edc6d",
   "metadata": {
    "id": "loop"
   },
   "source": [
    "--- \n",
    "\n",
    "## IV. Entra√Ænement et Stabilit√©\n",
    "\n",
    "La boucle d'entra√Ænement Minimax reste la m√™me, mais nous utilisons la nouvelle architecture et l'initialisation des poids sp√©cialis√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f27c5",
   "metadata": {
    "id": "train_dcgan"
   },
   "outputs": [],
   "source": [
    "# Initialisation des mod√®les et application des poids\n",
    "G = Generator(latent_dim).to(device).apply(weights_init)\n",
    "D = Discriminator().to(device).apply(weights_init)\n",
    "\n",
    "# Optimiseurs (Adam avec betas ajust√©s)\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() \n",
    "\n",
    "# Bruit fixe pour la visualisation\n",
    "fixed_noise = torch.randn(64, latent_dim, device=device)\n",
    "\n",
    "# Fonction utilitaire de visualisation (adapt√©e pour [-1, 1] -> [0, 1] pour matplotlib)\n",
    "def show_grid(grid, title=\"\", figsize=(10, 10)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(title)\n",
    "    # Inverse la normalisation pour l'affichage : [-1, 1] -> [0, 1]\n",
    "    grid = (grid + 1) / 2\n",
    "    plt.imshow(np.transpose(grid.numpy(), (1, 2, 0)), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def train_dcgan(G, D, G_optimizer, D_optimizer, criterion, dataloader, epochs, latent_dim, device):\n",
    "    \n",
    "    for epoch in trange(epochs, desc=\"Entra√Ænement DCGAN\"):\n",
    "        for i, (real_images, _) in enumerate(dataloader):\n",
    "            \n",
    "            # Les images sont d√©j√† en [-1, 1] et en format 4D (batch, 1, 28, 28)\n",
    "            real_images = real_images.to(device)\n",
    "            b_size = real_images.size(0)\n",
    "            \n",
    "            # Cibles pour BCEWithLogitsLoss\n",
    "            real_labels = torch.full((b_size, 1), 1.0, device=device)\n",
    "            fake_labels = torch.full((b_size, 1), 0.0, device=device)\n",
    "\n",
    "            # ===============================================\n",
    "            # 1. Mise √† jour du Discriminateur (D)\n",
    "            # ===============================================\n",
    "            D.zero_grad()\n",
    "\n",
    "            # 1a. Loss VRAI\n",
    "            output = D(real_images)\n",
    "            D_loss_real = criterion(output, real_labels)\n",
    "\n",
    "            # 1b. Loss FAUX\n",
    "            noise = torch.randn(b_size, latent_dim, device=device)\n",
    "            fake = G(noise)\n",
    "            output = D(fake.detach()) # D.detach()!\n",
    "            D_loss_fake = criterion(output, fake_labels)\n",
    "\n",
    "            # 1c. R√©tropropagation D\n",
    "            D_loss = D_loss_real + D_loss_fake\n",
    "            D_loss.backward()\n",
    "            D_optimizer.step()\n",
    "\n",
    "            # ===============================================\n",
    "            # 2. Mise √† jour du G√©n√©rateur (G)\n",
    "            # ===============================================\n",
    "            G.zero_grad()\n",
    "            \n",
    "            # G veut que D classe les fausses images comme VRAIES (cible = 1)\n",
    "            output = D(fake) \n",
    "            G_loss = criterion(output, real_labels) \n",
    "            \n",
    "            G_loss.backward()\n",
    "            G_optimizer.step()\n",
    "            \n",
    "        tqdm.write(f\"Epoch {epoch+1:2d} | D Loss: {D_loss.item():.4f} | G Loss: {G_loss.item():.4f}\")\n",
    "        \n",
    "        # 3. Visualisation\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            G.eval()\n",
    "            with torch.no_grad():\n",
    "                generated_images = G(fixed_noise).cpu()\n",
    "                show_grid(make_grid(generated_images, 8), title=f\"DCGAN G√©n√©ration √âpoque {epoch+1}\")\n",
    "            G.train()\n",
    "\n",
    "# train_dcgan(G, D, G_optimizer, D_optimizer, criterion, train_dataloader, epochs, latent_dim, device) # <-- D√âCOMMENTER POUR LANCER L'ENTRAINEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feafcbf",
   "metadata": {
    "id": "q4"
   },
   "source": [
    "### Question  (Q4.1)\n",
    "\n",
    "Quelle est la fonction de `weights_init(m)` ? Pourquoi est-il consid√©r√© comme une **bonne pratique** d'initialiser les poids des couches convolutionnelles avec une distribution Gaussienne centr√©e √† $0$ avec un petit √©cart-type ($0.02$) dans les DCGANs, plut√¥t que d'utiliser l'initialisation par d√©faut de PyTorch ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb16988",
   "metadata": {
    "id": "synthesis"
   },
   "source": [
    "--- \n",
    "\n",
    "## V. Synth√®se et Ouverture (Post-Entra√Ænement)\n",
    "\n",
    "Analysez les r√©sultats de votre DCGAN apr√®s l'entra√Ænement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72c216f",
   "metadata": {
    "id": "final_questions"
   },
   "source": [
    "### Questions Finales\n",
    "\n",
    "1.  **Stabilit√© :** Apr√®s l'entra√Ænement, la perte de $D$ (D Loss) est-elle proche de 0.69 ? Comparez la stabilit√© de l'entra√Ænement de ce DCGAN √† celle du MLP-GAN pr√©c√©dent. Comment la Normalisation par Batch a-t-elle potentiellement contribu√© √† cette diff√©rence ?\n",
    "2.  **Qualit√© d'Image :** D√©crivez la diff√©rence de qualit√© des images g√©n√©r√©es par le DCGAN par rapport au MLP-GAN. Quelles structures sont mieux captur√©es gr√¢ce √† l'utilisation des convolutions ?\n",
    "3.  **D√©fis :** Bien que les DCGANs soient plus stables, ils sont toujours sujets au **Mode Collapse**. D√©crivez bri√®vement comment l'architecture DCGAN tente *indirectement* de le pr√©venir (Indice : diversit√© des cartes de caract√©ristiques).\n",
    "4.  **Ouverture (WGAN) :** Le prochain d√©fi majeur des GANs concerne le choix de la fonction de co√ªt. Citez le probl√®me principal de la divergence de Jensen-Shannon (utilis√©e par BCE) lorsque les distributions r√©elles et g√©n√©r√©es sont s√©par√©es. Quel mod√®le de GAN c√©l√®bre (ex: WGAN) tente de r√©soudre ce probl√®me en utilisant une distance alternative (la distance de Wasserstein) ? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
