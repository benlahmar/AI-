{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† S√©ance 2 : NumPy - Mise en Forme, Diffusion et Filtrage\n",
    "#### Auteur: Pr BENLAHMAR EL HABIB\n",
    "\n",
    "## üéØ Objectifs de la S√©ance 2\n",
    "\n",
    "Cette session se concentre sur les techniques qui optimisent la manipulation et l'ajustement des donn√©es num√©riques, comp√©tences essentielles pour les mod√®les d'IA (Deep Learning notamment).\n",
    "\n",
    "* Ma√Ætriser la **Mise en forme** (`reshape`) et la **Transposition** (`T`).\n",
    "* Comprendre et appliquer la **Diffusion** (*Broadcasting*).\n",
    "* Utiliser l'**Indexation Bool√©enne** pour le filtrage conditionnel.\n",
    "* Synth√©tiser le concept de **Vectorisation** pour la normalisation de donn√©es.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mise en Forme et Transposition\n",
    "\n",
    "La **forme** (`shape`) d'un tableau doit souvent √™tre ajust√©e pour s'adapter aux exigences des op√©rations (ex: multiplier une matrice de poids par un vecteur d'entr√©e). \n",
    "\n",
    "### ‚úèÔ∏è Exercice 4.1 (Reshape et Transposition)\n",
    "\n",
    "Soit un vecteur `V` contenant 12 √©l√©ments (de 0 √† 11) :\n",
    "\n",
    "1.  Utilisez `.reshape()` pour transformer `V` en une matrice **3 lignes x 4 colonnes** (`M1`).\n",
    "2.  Transformez `M1` en une matrice **4 lignes x 3 colonnes** (`M2`) en utilisant **`.T`** (Transposition).\n",
    "3.  Cr√©ez un vecteur ligne (1D) : `v_ligne = np.array([1, 2, 3])`. Utilisez `np.newaxis` pour le transformer en un **vecteur colonne** 2D (forme (3, 1))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "V = np.arange(12)\n",
    "print(f\"Vecteur V (shape {V.shape}) : {V}\\n\")\n",
    "\n",
    "# 1. Reshape en 3x4\n",
    "M1 = V.reshape(3, 4)\n",
    "print(f\"Matrice M1 (shape {M1.shape}) : \\n{M1}\\n\")\n",
    "\n",
    "# 2. Transposition en 4x3\n",
    "M2 = M1.T\n",
    "print(f\"Matrice M2 Transpos√©e (shape {M2.shape}) : \\n{M2}\\n\")\n",
    "\n",
    "# 3. Vecteur colonne\n",
    "v_ligne = np.array([1, 2, 3])\n",
    "v_colonne = v_ligne[:, np.newaxis] # Ajoute une dimension apr√®s la virgule\n",
    "print(f\"Vecteur colonne (shape {v_colonne.shape}) : \\n{v_colonne}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## 5. Diffusion (Broadcasting)\n",
    "\n",
    "Le **Broadcasting** permet d'effectuer des op√©rations arithm√©tiques entre des tableaux de formes diff√©rentes, √† condition que NumPy puisse logiquement **\"√©tirer\"** (r√©p√©ter) le tableau le plus petit pour correspondre au plus grand. \n",
    "\n",
    "### ‚úèÔ∏è Exercice 5.1 (Application de Biais par Broadcasting)\n",
    "\n",
    "Nous allons simuler l'ajout d'un **vecteur de biais** (`b`) √† une **matrice de features** (`F`).\n",
    "\n",
    "1.  D√©finissez la matrice de features `F` (forme 3x2).\n",
    "2.  D√©finissez le vecteur de biais `b` (forme 2, qui est interpr√©t√© comme 1x2).\n",
    "3.  Calculez la somme `R = F + b`. **Expliquez** dans une cellule Markdown comment le vecteur `b` a √©t√© appliqu√© √† chaque ligne de `F`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = np.array([[10, 20], [30, 40], [50, 60]]) # Matrice 3x2\n",
    "b = np.array([1, 2]) # Vecteur 1D (taille 2)\n",
    "\n",
    "R = F + b\n",
    "\n",
    "print(f\"Matrice F : \\n{F}\\n\")\n",
    "print(f\"Vecteur b : {b}\\n\")\n",
    "print(f\"R√©sultat F + b (R) : \\n{R}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explication du Broadcasting :**\n",
    "*(√âcrivez ici comment le vecteur [1, 2] a √©t√© r√©p√©t√© implicitement pour √™tre ajout√© √† chaque ligne de la matrice F.)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## 6. Indexation Avanc√©e (Indexation Bool√©enne)\n",
    "\n",
    "L'**Indexation Bool√©enne** est la m√©thode standard pour filtrer les donn√©es en fonction d'une condition. Un masque bool√©en (`True`/`False`) de la m√™me taille que le tableau est cr√©√©, et seules les valeurs correspondant √† `True` sont conserv√©es.\n",
    "\n",
    "### ‚úèÔ∏è Exercice 6.1 (Filtrage Conditionnel - ReLU)\n",
    "\n",
    "Nous allons simuler la fonction d'activation **ReLU** (`Rectified Linear Unit`), qui met √† z√©ro toutes les valeurs n√©gatives.\n",
    "\n",
    "Soit un tableau de valeurs d'activation : `Activations = np.array([0.9, -0.1, 0.5, 1.2, -0.3, 0.7])`.\n",
    "\n",
    "1.  Cr√©ez un **masque bool√©en** qui est `True` pour toutes les activations **positives** (`> 0`).\n",
    "2.  Utilisez ce masque pour extraire et afficher uniquement les activations positives.\n",
    "3.  En une seule ligne, utilisez l'indexation bool√©enne pour remplacer toutes les activations n√©gatives ou nulles par **0** (simulation de ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Activations = np.array([0.9, -0.1, 0.5, 1.2, -0.3, 0.7])\n",
    "\n",
    "# 1. Masque Bool√©en\n",
    "masque_positif = Activations > 0\n",
    "print(f\"Masque Bool√©en : {masque_positif}\\n\")\n",
    "\n",
    "# 2. Extraction des valeurs > 0\n",
    "activations_positives = Activations[masque_positif]\n",
    "print(f\"Activations positives (extraites) : {activations_positives}\\n\")\n",
    "\n",
    "# 3. Simulation de ReLU (mise √† z√©ro des n√©gatifs)\n",
    "Activations[Activations <= 0] = 0\n",
    "print(f\"R√©sultat final (ReLU) : {Activations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## 7. Synth√®se et Normalisation Vectoris√©e\n",
    "\n",
    "Combinons **Op√©rations Math√©matiques**, **Broadcasting** et **Fonctions Agr√©g√©es** pour effectuer une normalisation standard (Z-Score) en une seule √©tape vectoris√©e.\n",
    "\n",
    "### ‚úèÔ∏è Exercice 7.1 (Normalisation Z-Score)\n",
    "\n",
    "L'√©quation de normalisation par colonne est :\n",
    "$$\\text{Normalis√©} = (\\text{Matrice} - \\text{Moyenne}) / \\text{√âcart\\_Type}$$\n",
    "\n",
    "1.  Cr√©ez une matrice al√©atoire 4x3 (`X`).\n",
    "2.  Calculez la **moyenne** de `X` sur l'**axe des colonnes** (`axis=0`).\n",
    "3.  Calculez l'**√©cart-type** (`std`) de `X` sur l'**axe des colonnes** (`axis=0`).\n",
    "4.  Appliquez la formule de normalisation compl√®te en une seule ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(4, 3) * 10 # Matrice 4x3 de valeurs entre 0 et 10\n",
    "print(f\"Matrice de d√©part X : \\n{X}\\n\")\n",
    "\n",
    "# 2. Calcul des statistiques par colonne (axis=0)\n",
    "moyenne = X.mean(axis=0)\n",
    "std_dev = X.std(axis=0)\n",
    "\n",
    "print(f\"Moyennes par colonne : {moyenne}\\n\")\n",
    "\n",
    "# 4. Normalisation compl√®te (le Broadcasting g√®re l'application de moyenne et std_dev √† chaque ligne)\n",
    "X_normalise = (X - moyenne) / std_dev\n",
    "\n",
    "print(f\"Matrice normalis√©e (Z-Score) : \\n{X_normalise}\")\n",
    "\n",
    "# V√©rification (la nouvelle moyenne de chaque colonne doit √™tre tr√®s proche de 0)\n",
    "print(f\"\\nMoyenne apr√®s normalisation : {X_normalise.mean(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "##  Conclusion de l'Atelier NumPy\n",
    "\n",
    "Vous ma√Ætrisez maintenant les techniques qui permettent √† NumPy d'√™tre performant :\n",
    "\n",
    "* **Mise en Forme** pour pr√©parer les donn√©es.\n",
    "* **Broadcasting** pour l'ajout efficace de biais ou la soustraction de moyennes.\n",
    "* **Indexation Bool√©enne** pour le filtrage et les activations.\n",
    "\n",
    "Ces comp√©tences sont fondamentales pour construire et manipuler les **tenseurs** en Deep Learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
