{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e12255b",
   "metadata": {},
   "source": [
    "# TP NLP ‚Äî T3 : **Attention** (Bahdanau) sur Seq2Seq ‚Äî Master IA\n",
    "\n",
    "Ce notebook correspond au **Tutoriel 3 (T3)** : ajout d‚Äôun m√©canisme d‚Äô**attention** √† un mod√®le Seq2Seq.\n",
    "On utilise un **encodeur BiLSTM** et un **d√©codeur LSTM avec attention additive (Bahdanau)**.\n",
    "\n",
    "---\n",
    "## üéØ Objectifs p√©dagogiques\n",
    "- Expliquer le **goulot d‚Äô√©tranglement** du Seq2Seq (un seul vecteur contexte)\n",
    "- Impl√©menter l‚Äô**attention additive** (Bahdanau)\n",
    "- Visualiser les **poids d‚Äôattention** (heatmap)\n",
    "- Comparer qualitativement et quantitativement avec T2\n",
    "\n",
    "---\n",
    "## üß† Intuition\n",
    "Avec l‚Äôattention, le d√©codeur calcule √† chaque pas un vecteur contexte :\n",
    "- score d‚Äôalignement entre l‚Äô√©tat du d√©codeur et chaque √©tat encodeur\n",
    "- softmax ‚Üí poids d‚Äôattention\n",
    "- somme pond√©r√©e ‚Üí contexte\n",
    "\n",
    "---\n",
    "## üß© Probl√®me √©tudi√©\n",
    "On reprend : **inversion de s√©quence**\n",
    "`[1, 5, 7, 3] ‚Üí [3, 7, 5, 1]`\n",
    "\n",
    "Ce probl√®me rend l‚Äôattention facilement interpr√©table : le mod√®le doit ‚Äúpointer‚Äù sur la bonne position source.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aef4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b99a17",
   "metadata": {},
   "source": [
    "## 1) Param√®tres et vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b8c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "V = 20\n",
    "MIN_LEN, MAX_LEN = 3, 12\n",
    "\n",
    "TRAIN_SIZE = 9000\n",
    "VALID_SIZE = 1000\n",
    "TEST_SIZE  = 1000\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EMBED_DIM  = 64\n",
    "HIDDEN_DIM = 128  # hidden du d√©codeur\n",
    "\n",
    "EPOCHS = 10\n",
    "LR = 1e-3\n",
    "TEACHER_FORCING_RATIO = 0.7\n",
    "\n",
    "PAD = 0\n",
    "SOS = V + 1\n",
    "EOS = V + 2\n",
    "VOCAB_SIZE = V + 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da952d",
   "metadata": {},
   "source": [
    "## 2) Dataset + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d71b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_pair():\n",
    "    L = random.randint(MIN_LEN, MAX_LEN)\n",
    "    src = [random.randint(1, V) for _ in range(L)]\n",
    "    tgt = [SOS] + list(reversed(src)) + [EOS]\n",
    "    return src, tgt\n",
    "\n",
    "class ReverseDataset(Dataset):\n",
    "    def __init__(self, n):\n",
    "        self.data = [generate_pair() for _ in range(n)]\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self, i): return self.data[i]\n",
    "\n",
    "def pad(seqs, pad_value=PAD):\n",
    "    m = max(len(s) for s in seqs)\n",
    "    return torch.tensor([s+[pad_value]*(m-len(s)) for s in seqs], dtype=torch.long)\n",
    "\n",
    "def collate(batch):\n",
    "    src = pad([b[0] for b in batch])\n",
    "    tgt = pad([b[1] for b in batch])\n",
    "    tgt_in  = tgt[:, :-1]\n",
    "    tgt_out = tgt[:, 1:]\n",
    "    return src, tgt_in, tgt_out\n",
    "\n",
    "train_loader = DataLoader(ReverseDataset(TRAIN_SIZE), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate)\n",
    "valid_loader = DataLoader(ReverseDataset(VALID_SIZE), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate)\n",
    "test_loader  = DataLoader(ReverseDataset(TEST_SIZE),  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a6a7b2",
   "metadata": {},
   "source": [
    "## 3) Encodeur BiLSTM\n",
    "\n",
    "Pour l‚Äôattention, on a besoin de **tous** les √©tats de l‚Äôencodeur (pas seulement l‚Äô√©tat final).\n",
    "L‚Äôencodeur retourne :\n",
    "- `enc_outputs` : √©tats par pas de temps (dimension 2*HIDDEN_DIM car bidirectionnel)\n",
    "- √©tat initial du d√©codeur `(h0, c0)` obtenu en concat√©nant forward/backward puis projection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BiEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc_h = nn.Linear(2*hidden_dim, hidden_dim)\n",
    "        self.fc_c = nn.Linear(2*hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        emb = self.emb(src)                          # [B,T,E]\n",
    "        enc_outputs, (h, c) = self.lstm(emb)         # enc_outputs [B,T,2H], h,c [2,B,H]\n",
    "        h_cat = torch.cat([h[0], h[1]], dim=1)        # [B,2H]\n",
    "        c_cat = torch.cat([c[0], c[1]], dim=1)        # [B,2H]\n",
    "        h0 = torch.tanh(self.fc_h(h_cat)).unsqueeze(0) # [1,B,H]\n",
    "        c0 = torch.tanh(self.fc_c(c_cat)).unsqueeze(0) # [1,B,H]\n",
    "        return enc_outputs, (h0, c0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a302a8bb",
   "metadata": {},
   "source": [
    "## 4) Attention additive (Bahdanau)\n",
    "\n",
    "Score d‚Äôalignement : `e_{t,i} = v^T tanh(W_s s_t + W_h h_i)`\n",
    "Puis :\n",
    "- `alpha = softmax(e)` (avec mask pour ignorer PAD)\n",
    "- `context = Œ£ alpha_i * h_i`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b46ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, dec_hidden, enc_hidden2):\n",
    "        super().__init__()\n",
    "        self.Ws = nn.Linear(dec_hidden, dec_hidden, bias=False)\n",
    "        self.Wh = nn.Linear(enc_hidden2, dec_hidden, bias=False)\n",
    "        self.v  = nn.Linear(dec_hidden, 1, bias=False)\n",
    "\n",
    "    def forward(self, s_t, enc_outputs, src_mask):\n",
    "        # s_t: [B,Hdec], enc_outputs: [B,Tsrc,2Henc], src_mask: [B,Tsrc]\n",
    "        s = self.Ws(s_t).unsqueeze(1)               # [B,1,H]\n",
    "        h = self.Wh(enc_outputs)                    # [B,T,H]\n",
    "        e = self.v(torch.tanh(s + h)).squeeze(-1)   # [B,T]\n",
    "        e = e.masked_fill(src_mask == 0, -1e9)\n",
    "        alpha = torch.softmax(e, dim=1)             # [B,T]\n",
    "        context = torch.bmm(alpha.unsqueeze(1), enc_outputs).squeeze(1)  # [B,2Henc]\n",
    "        return context, alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682c2f7",
   "metadata": {},
   "source": [
    "## 5) D√©codeur avec attention\n",
    "\n",
    "√Ä chaque pas :\n",
    "1. Calcul du contexte via attention\n",
    "2. Concat(embedding token courant, contexte)\n",
    "3. LSTM ‚Üí nouvel √©tat\n",
    "4. Pr√©diction √† partir de Concat(√©tat d√©codeur, contexte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ec390",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, dec_hidden, enc_hidden2):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD)\n",
    "        self.attn = BahdanauAttention(dec_hidden, enc_hidden2)\n",
    "        self.lstm = nn.LSTM(embed_dim + enc_hidden2, dec_hidden, batch_first=True)\n",
    "        self.fc   = nn.Linear(dec_hidden + enc_hidden2, vocab_size)\n",
    "\n",
    "    def forward(self, x_tok, state, enc_outputs, src_mask):\n",
    "        # x_tok: [B,1], state: (h,c) each [1,B,Hdec]\n",
    "        h, c = state\n",
    "        s_t = h.squeeze(0)  # [B,Hdec]\n",
    "\n",
    "        context, alpha = self.attn(s_t, enc_outputs, src_mask)  # context [B,2Henc]\n",
    "        emb = self.emb(x_tok)                                   # [B,1,E]\n",
    "        lstm_in = torch.cat([emb.squeeze(1), context], dim=1).unsqueeze(1)  # [B,1,E+2Henc]\n",
    "\n",
    "        out, (h, c) = self.lstm(lstm_in, (h, c))                 # out [B,1,Hdec]\n",
    "        s_out = out.squeeze(1)                                   # [B,Hdec]\n",
    "\n",
    "        logits = self.fc(torch.cat([s_out, context], dim=1)).unsqueeze(1)  # [B,1,V]\n",
    "        return logits, (h, c), alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3795b7c",
   "metadata": {},
   "source": [
    "## 6) Mod√®le Seq2Seq avec attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf34bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttnSeq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, tgt_in, tf_ratio=0.7):\n",
    "        B, Tsrc = src.shape\n",
    "        _, Ttgt = tgt_in.shape\n",
    "\n",
    "        src_mask = (src != PAD).long()\n",
    "\n",
    "        enc_outputs, state = self.encoder(src)  # enc_outputs [B,Tsrc,2H], state ([1,B,H],[1,B,H])\n",
    "        logits_all = torch.zeros(B, Ttgt, VOCAB_SIZE, device=src.device)\n",
    "        attn_all   = torch.zeros(B, Ttgt, Tsrc, device=src.device)\n",
    "\n",
    "        x = tgt_in[:, 0].unsqueeze(1)  # SOS\n",
    "        for t in range(Ttgt):\n",
    "            step_logits, state, alpha = self.decoder(x, state, enc_outputs, src_mask)\n",
    "            logits_all[:, t:t+1, :] = step_logits\n",
    "            attn_all[:, t, :] = alpha\n",
    "\n",
    "            pred = step_logits.argmax(-1)\n",
    "            if t + 1 < Ttgt:\n",
    "                x = tgt_in[:, t+1].unsqueeze(1) if random.random() < tf_ratio else pred\n",
    "\n",
    "        return logits_all, attn_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c5657d",
   "metadata": {},
   "source": [
    "## 7) Entra√Ænement / √©valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AttnSeq2Seq(\n",
    "    BiEncoder(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM),\n",
    "    AttnDecoder(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, enc_hidden2=2*HIDDEN_DIM)\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "def token_acc(logits, targets):\n",
    "    pred = logits.argmax(-1)\n",
    "    mask = targets != PAD\n",
    "    correct = (pred == targets) & mask\n",
    "    return correct.sum().item() / mask.sum().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def exact_match(logits, targets):\n",
    "    pred = logits.argmax(-1).detach().cpu().numpy()\n",
    "    gold = targets.detach().cpu().numpy()\n",
    "    ok = 0\n",
    "    for i in range(gold.shape[0]):\n",
    "        g = [t for t in gold[i].tolist() if t != PAD]\n",
    "        p = [t for t in pred[i].tolist() if t != PAD]\n",
    "        ok += int(p == g)\n",
    "    return ok / gold.shape[0]\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    total_loss, total_em = 0.0, 0.0\n",
    "\n",
    "    for src, tgt_in, tgt_out in loader:\n",
    "        src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(src, tgt_in, tf_ratio=TEACHER_FORCING_RATIO)\n",
    "        else:\n",
    "            logits, _ = model(src, tgt_in, tf_ratio=0.0)\n",
    "\n",
    "        B, T, V = logits.shape\n",
    "        loss = criterion(logits.reshape(B*T, V), tgt_out.reshape(B*T))\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_em   += exact_match(logits, tgt_out)\n",
    "\n",
    "    n = len(loader)\n",
    "    return total_loss/n, total_em/n\n",
    "\n",
    "hist = {\"tr_loss\":[], \"va_loss\":[], \"tr_em\":[], \"va_em\":[]}\n",
    "\n",
    "for e in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_em = run_epoch(train_loader, train=True)\n",
    "    va_loss, va_em = run_epoch(valid_loader, train=False)\n",
    "\n",
    "    hist[\"tr_loss\"].append(tr_loss); hist[\"va_loss\"].append(va_loss)\n",
    "    hist[\"tr_em\"].append(tr_em);     hist[\"va_em\"].append(va_em)\n",
    "\n",
    "    print(f\"Epoch {e:02d} | train loss {tr_loss:.4f} EM {tr_em:.3f} | valid loss {va_loss:.4f} EM {va_em:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecb017a",
   "metadata": {},
   "source": [
    "## 8) Courbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42489d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(hist[\"tr_loss\"], label=\"train loss\")\n",
    "plt.plot(hist[\"va_loss\"], label=\"valid loss\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.legend(); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hist[\"tr_em\"], label=\"train exact match\")\n",
    "plt.plot(hist[\"va_em\"], label=\"valid exact match\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"exact match\"); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933f9148",
   "metadata": {},
   "source": [
    "## 9) Inference greedy + attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def greedy_decode_with_attention(model, src_seq, max_len=30):\n",
    "    model.eval()\n",
    "    src = torch.tensor([src_seq], dtype=torch.long, device=device)  # [1,Tsrc]\n",
    "    src_mask = (src != PAD).long()\n",
    "    enc_outputs, state = model.encoder(src)\n",
    "\n",
    "    x = torch.tensor([[SOS]], dtype=torch.long, device=device)\n",
    "    out_tokens = []\n",
    "    attn_weights = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        logits, state, alpha = model.decoder(x, state, enc_outputs, src_mask)\n",
    "        pred = logits.argmax(-1)\n",
    "        tok = pred.item()\n",
    "        out_tokens.append(tok)\n",
    "        attn_weights.append(alpha.squeeze(0).detach().cpu().numpy())\n",
    "\n",
    "        x = pred\n",
    "        if tok == EOS:\n",
    "            break\n",
    "\n",
    "    return out_tokens, np.stack(attn_weights, axis=0)\n",
    "\n",
    "example_src = [1, 5, 7, 3]\n",
    "pred_tokens, attn = greedy_decode_with_attention(model, example_src, max_len=20)\n",
    "print(\"src :\", example_src)\n",
    "print(\"pred:\", pred_tokens)\n",
    "print(\"gold:\", list(reversed(example_src)) + [EOS])\n",
    "print(\"attn shape:\", attn.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5053156a",
   "metadata": {},
   "source": [
    "## 10) Heatmap des poids d‚Äôattention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_attention(attn, src_seq, pred_seq):\n",
    "    src_labels = [str(x) for x in src_seq]\n",
    "    tgt_labels = [str(x) for x in pred_seq]\n",
    "\n",
    "    plt.figure(figsize=(max(6, len(src_labels)), max(4, len(tgt_labels)*0.6)))\n",
    "    plt.imshow(attn, aspect=\"auto\")\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(len(src_labels)), src_labels)\n",
    "    plt.yticks(range(len(tgt_labels)), tgt_labels)\n",
    "    plt.xlabel(\"Source tokens\")\n",
    "    plt.ylabel(\"Predicted tokens\")\n",
    "    plt.title(\"Attention weights (Bahdanau)\")\n",
    "    plt.show()\n",
    "\n",
    "show_attention(attn, example_src, [t for t in pred_tokens if t != PAD])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d94c396",
   "metadata": {},
   "source": [
    "## 11) Test final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84271ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_test(model, loader):\n",
    "    model.eval()\n",
    "    total_em = 0.0\n",
    "    for src, tgt_in, tgt_out in loader:\n",
    "        src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
    "        logits, _ = model(src, tgt_in, tf_ratio=0.0)\n",
    "        total_em += exact_match(logits, tgt_out)\n",
    "    return total_em / len(loader)\n",
    "\n",
    "test_em = evaluate_test(model, test_loader)\n",
    "print(f\"TEST exact-match: {test_em:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb6df8",
   "metadata": {},
   "source": [
    "---\n",
    "## 12) Questions √† rendre\n",
    "\n",
    "1. Donnez la d√©finition du goulot d‚Äô√©tranglement dans T1/T2.  \n",
    "2. √âcrivez les √©tapes de calcul de l‚Äôattention (score ‚Üí softmax ‚Üí contexte).  \n",
    "3. Interpr√©tez une heatmap : que signifie une **ligne** (temps de sortie) ? une **colonne** (position source) ?  \n",
    "4. Pourquoi l‚Äôattention aide-t-elle sur les longues s√©quences ?  \n",
    "5. Quelles diff√©rences avec la **self-attention** du Transformer (T4) ?  \n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
