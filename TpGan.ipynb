{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b885a75b",
   "metadata": {
    "id": "intro"
   },
   "source": [
    "# üéì Travaux Pratiques : Introduction P√©dagogique aux GANs (MLP-GAN)\n",
    "\n",
    "**Auteur :**Benlahmar Habib\n",
    "\n",
    "\n",
    "## Objectifs P√©dagogiques de l'Atelier\n",
    "\n",
    "1.  **Conceptualisation :** Comprendre le principe du **jeu antagoniste** et l'analogie du Faux-Monnayeur vs. D√©tective.\n",
    "2.  **Th√©orie :** D√©cortiquer la fonction de co√ªt **Minimax** qui r√©git l'apprentissage des GANs.\n",
    "3.  **Impl√©mentation Basique :** Mettre en ≈ìuvre un GAN simple (bas√© sur des couches lin√©aires/MLP) avec PyTorch sur la base Fashion-MNIST. \n",
    "4.  **Analyse :** Comprendre les d√©fis li√©s √† la stabilit√© de l'entra√Ænement des GANs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a721b7a3",
   "metadata": {
    "id": "concept"
   },
   "source": [
    "--- \n",
    "\n",
    "## I. Introduction Conceptuelle : Le Jeu Antagoniste\n",
    "\n",
    "Les **Generative Adversarial Networks** (R√©seaux G√©n√©ratifs Antagonistes) sont compos√©s de deux r√©seaux qui s'affrontent dans un jeu √† somme nulle : le **G√©n√©rateur (G)** et le **Discriminateur (D)**. \n",
    "\n",
    "| Composant | R√¥le Analogue | R√¥le Technique | Objectif | \n",
    "| :--- | :--- | :--- | :--- | \n",
    "| **G√©n√©rateur (G)** | Le Faux-Monnayeur | Prend un bruit al√©atoire $\\mathbf{z}$ et cr√©e $\\mathbf{x}_{\\text{faux}}$. | Tromper $D$ pour que $D$ classe les faux comme VRAIS (1). | \n",
    "| **Discriminateur (D)** | Le D√©tective | Classifie une image comme VRAIE (1) ou FAUSSE (0). | Identifier parfaitement la provenance de l'image (maximiser l'exactitude). | \n",
    "\n",
    "### üìå 1.1. La Fonction Objectif (Minimax Game)\n",
    "\n",
    "L'entra√Ænement du GAN est formul√© comme la recherche d'un **√©quilibre de Nash** dans le jeu Minimax :\n",
    "\n",
    "$$\\min_G \\max_D V(D, G) = \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}(\\mathbf{x})} [\\log D(\\mathbf{x})] + \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}(\\mathbf{z})} [\\log (1 - D(G(\\mathbf{z})))]$$\n",
    "\n",
    "* **$\\max_D$ (Maximisation par D) :** Le Discriminateur veut que $D(\\mathbf{x})$ (vrai) soit proche de 1 et que $D(G(\\mathbf{z}))$ (faux) soit proche de 0. Cela maximise l'expression.\n",
    "* **$\\min_G$ (Minimisation par G) :** Le G√©n√©rateur veut que $D(G(\\mathbf{z}))$ (faux) soit proche de 1 (pour tromper $D$). Cela minimise le second terme de l'expression.\n",
    "\n",
    "**L'√©quilibre id√©al** est atteint lorsque $D(\\mathbf{x}) = D(G(\\mathbf{z})) = 0.5$ pour tout $\\mathbf{x}$, car $D$ ne peut plus faire la diff√©rence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bb7e54",
   "metadata": {
    "id": "q1"
   },
   "source": [
    "### Question  (Q1.1)\n",
    "\n",
    "Si, au d√©but de l'entra√Ænement, le Discriminateur renvoie $D(\\mathbf{x}) = 0.9$ pour les vraies images et $D(G(\\mathbf{z})) = 0.1$ pour les fausses images, comment cela impacte-t-il l'apprentissage du G√©n√©rateur $G$ √† ce stade ? (Indice : regardez le terme $\\log (1 - D(G(\\mathbf{z})))$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b2190",
   "metadata": {
    "id": "config"
   },
   "source": [
    "--- \n",
    "\n",
    "## II. Pr√©paration et Architecture (MLP-GAN)\n",
    "\n",
    "Nous utilisons des r√©seaux de neurones multi-couches (MLP) simples pour d√©marrer. Les images 28x28 seront mises √† plat en vecteurs de 784 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b046ca0",
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Ex√©cution sur {device}\")\n",
    "\n",
    "# Hyperparam√®tres\n",
    "image_size = 28 * 28  # 784\n",
    "latent_dim = 100       # Dimension du bruit z\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "lr = 0.0002 # Taux d'apprentissage souvent bas pour la stabilit√© des GANs\n",
    "\n",
    "# Chargement des donn√©es et aplatissement des images (ToTensor() + normalisation [0, 1])\n",
    "transform = ToTensor()\n",
    "train_dataset = FashionMNIST(root='./data/FashionMNIST', train=True, download=True, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ada399",
   "metadata": {
    "id": "g-model"
   },
   "source": [
    "### 2.2. Le G√©n√©rateur (G)\n",
    "\n",
    "Input : Vecteur de bruit $z$ (`latent_dim`). Output : Vecteur image $\\mathbf{x}'$ (`image_size`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fbc339",
   "metadata": {
    "id": "generator"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, img_dim),\n",
    "            nn.Sigmoid() # Sigmoid pour garantir la sortie [0, 1] (normalisation simple)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ba610",
   "metadata": {
    "id": "d-model"
   },
   "source": [
    "### 2.3. Le Discriminateur (D)\n",
    "\n",
    "Input : Vecteur image $x$ (`image_size`). Output : Score scalaire (logit) qui sera transform√© en probabilit√© [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b892047",
   "metadata": {
    "id": "discriminator"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_dim, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3), \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1) # Sortie finale sans activation (logits)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e80e148",
   "metadata": {
    "id": "init"
   },
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "G = Generator(latent_dim, image_size).to(device)\n",
    "D = Discriminator(image_size).to(device)\n",
    "\n",
    "# Optimiseurs : Le choix d'Adam et des betas=(0.5, 0.999) est standard pour les GANs.\n",
    "G_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "D_optimizer = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss : BCEWithLogitsLoss est recommand√© pour la stabilit√© num√©rique. Elle inclut Sigmoid.\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Bruit fixe pour suivre la progression de la g√©n√©ration\n",
    "fixed_noise = torch.randn(64, latent_dim, device=device) \n",
    "\n",
    "# Fonction utilitaire de visualisation (r√©utilis√©e du TP VAE)\n",
    "def show_grid(grid, title=\"\", figsize=(10, 10)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(title)\n",
    "    # Note: On utilise 'cmap=\"gray\"' car Fashion-MNIST est en niveaux de gris\n",
    "    plt.imshow(np.transpose(grid.numpy(), (1, 2, 0)), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971fe87",
   "metadata": {
    "id": "q2"
   },
   "source": [
    "### Question  (Q2.1)\n",
    "\n",
    "Observez les taux d'apprentissage. Pourquoi le taux d'apprentissage est-il souvent tr√®s bas (ici 0.0002) dans les GANs par rapport √† d'autres r√©seaux (souvent 0.001) ? Quel risque prend-on avec des taux d'apprentissage trop √©lev√©s pour $G$ ou $D$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447677e5",
   "metadata": {
    "id": "loop"
   },
   "source": [
    "--- \n",
    "\n",
    "## III. Boucle d'Entra√Ænement : L'Alternance Cruciale\n",
    "\n",
    "L'entra√Ænement s'effectue en deux sous-√©tapes par batch : d'abord on am√©liore $D$, puis on am√©liore $G$. C'est le c≈ìur du jeu antagoniste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963b0f0",
   "metadata": {
    "id": "train"
   },
   "outputs": [],
   "source": [
    "def train_gan(G, D, G_optimizer, D_optimizer, criterion, dataloader, epochs, latent_dim, device):\n",
    "    G.train(); D.train()\n",
    "    for epoch in trange(epochs, desc=\"Entra√Ænement GAN\"):\n",
    "        D_loss_total = 0\n",
    "        G_loss_total = 0\n",
    "        \n",
    "        for real_images, _ in dataloader:\n",
    "            \n",
    "            # --- Pr√©paration des donn√©es --- \n",
    "            real_images = real_images.view(-1, image_size).to(device)\n",
    "            current_batch_size = real_images.size(0)\n",
    "            \n",
    "            # Tenseurs de cibles (VRAI=1.0, FAUX=0.0)\n",
    "            # Utiliser des floats pour les cibles de BCE\n",
    "            real_labels = torch.ones(current_batch_size, 1, device=device)\n",
    "            fake_labels = torch.zeros(current_batch_size, 1, device=device)\n",
    "\n",
    "            # ===============================================\n",
    "            # 1. √âTAPE D : Am√©liorer le Discriminateur\n",
    "            # ===============================================\n",
    "            D_optimizer.zero_grad()\n",
    "\n",
    "            # 1a. Loss sur les images r√©elles (cible = 1)\n",
    "            D_real_pred = D(real_images)\n",
    "            D_real_loss = criterion(D_real_pred, real_labels)\n",
    "            \n",
    "            # 1b. G√©n√©rer les fausses images et calculer la loss (cible = 0)\n",
    "            noise = torch.randn(current_batch_size, latent_dim, device=device)\n",
    "            fake_images = G(noise) \n",
    "            \n",
    "            # ‚ö†Ô∏è POINT CL√â : .detach() pour arr√™ter la r√©tropropagation vers G\n",
    "            D_fake_pred = D(fake_images.detach()) \n",
    "            D_fake_loss = criterion(D_fake_pred, fake_labels)\n",
    "            \n",
    "            # 1c. R√©tropropagation de la loss totale de D\n",
    "            D_loss = D_real_loss + D_fake_loss\n",
    "            D_loss.backward()\n",
    "            D_optimizer.step()\n",
    "            \n",
    "            D_loss_total += D_loss.item()\n",
    "            \n",
    "            # ===============================================\n",
    "            # 2. √âTAPE G : Am√©liorer le G√©n√©rateur\n",
    "            # ===============================================\n",
    "            G_optimizer.zero_grad()\n",
    "            \n",
    "            # G veut que D pr√©dise 1 (VRAI) pour ses fausses images (pour le tromper)\n",
    "            # On r√©utilise fake_images, mais cette fois le graphe de G est attach√©.\n",
    "            G_pred = D(fake_images) \n",
    "            G_loss = criterion(G_pred, real_labels) # ‚ö†Ô∏è CIBLE = 1 (real_labels) pour la loss de G\n",
    "            \n",
    "            G_loss.backward()\n",
    "            G_optimizer.step()\n",
    "            \n",
    "            G_loss_total += G_loss.item()\n",
    "\n",
    "        # --- Affichage de l'√©volution (par √©poque) ---\n",
    "        avg_D_loss = D_loss_total / len(dataloader)\n",
    "        avg_G_loss = G_loss_total / len(dataloader)\n",
    "        tqdm.write(f\"Epoch {epoch+1:2d} | D Loss: {avg_D_loss:.4f} | G Loss: {avg_G_loss:.4f}\")\n",
    "        \n",
    "        # 4. Visualisation toutes les 5 √©poques\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            G.eval()\n",
    "            with torch.no_grad():\n",
    "                # G√©n√©rer 64 images √† partir du bruit fixe\n",
    "                generated_images = G(fixed_noise).cpu().view(64, 1, 28, 28)\n",
    "                show_grid(make_grid(generated_images, 8), title=f\"G√©n√©ration √âpoque {epoch+1}\")\n",
    "            G.train()\n",
    "\n",
    "# train_gan(G, D, G_optimizer, D_optimizer, criterion, train_dataloader, epochs, latent_dim, device) # <-- D√âCOMMENTER POUR LANCER L'ENTRAINEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf44d95",
   "metadata": {
    "id": "q3"
   },
   "source": [
    "### Question  (Q3.1)\n",
    "\n",
    "Dans l'√©tape d'entra√Ænement du Discriminateur, nous utilisons `.detach()` sur les `fake_images` g√©n√©r√©es par $G$. Quel est l'effet pr√©cis de cette m√©thode PyTorch dans le contexte des GANs, et pourquoi est-il essentiel pour l'entra√Ænement de $D$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe8f57",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "--- \n",
    "\n",
    "## IV. Analyse des R√©sultats et Questions de Synth√®se\n",
    "\n",
    "Une fois l'entra√Ænement termin√©, analysez les images g√©n√©r√©es et les courbes de perte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7152373",
   "metadata": {
    "id": "final_questions"
   },
   "source": [
    "### Questions Finales (Synth√®se et Ouverture)\n",
    "\n",
    "1.  **Interpr√©tation de la Perte $D$ :** Expliquez la valeur id√©ale vers laquelle la perte du Discriminateur devrait converger. Que signifie une $D$ Loss trop basse (proche de 0) en milieu ou fin d'entra√Ænement ?\n",
    "2.  **Probl√®me de Stabilit√© :** Le *Mode Collapse* est un d√©fi majeur des GANs. Expliquez ce ph√©nom√®ne et d√©crivez visuellement ce qu'il se passerait sur la grille de g√©n√©ration si votre mod√®le en √©tait victime.\n",
    "3.  **Avantage vs. VAE :** Par rapport au VAE que vous avez √©tudi√© pr√©c√©demment, quel est le principal avantage du GAN en termes de qualit√© visuelle des images g√©n√©r√©es ? Quelle en est la contrepartie (d√©savantage) ?\n",
    "4.  **Ouverture DCGAN :** Quel type d'architecture sera introduit dans la prochaine √©tape (DCGAN) pour remplacer les couches lin√©aires (MLP) ? Quel avantage les couches convolutionnelles apportent-elles pour la g√©n√©ration d'images, par rapport aux couches lin√©aires ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
