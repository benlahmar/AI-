{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21209c9f",
   "metadata": {},
   "source": [
    "# TP NLP ‚Äî Seq2Seq (LSTM) : Addition symbolique (caract√®re par caract√®re) ‚Äî Master IA\n",
    "\n",
    "Ce notebook propose un **TP complet** pour entra√Æner un mod√®le **Seq2Seq** (encodeur‚Äìd√©codeur) √† r√©aliser une **addition** √©crite sous forme de cha√Æne.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Int√©r√™t p√©dagogique (pourquoi ce probl√®me ?)\n",
    "\n",
    "L'addition symbolique est un **probl√®me jouet riche**, car il force le mod√®le √† apprendre :\n",
    "- un mapping **s√©quence ‚Üí s√©quence** avec **longueurs variables**,\n",
    "- la notion de **g√©n√©ration auto-r√©gressive** (un caract√®re apr√®s l‚Äôautre),\n",
    "- une forme de **raisonnement algorithmique** (retenues/carry),\n",
    "- les limites du Seq2Seq **sans attention** (goulot d‚Äô√©tranglement),\n",
    "- l‚Äôimpact de **teacher forcing** et de la **g√©n√©ralisation** (vers des nombres plus longs).\n",
    "\n",
    "> Contrairement √† l‚Äôinversion, ici on ne fait pas ‚Äúque‚Äù r√©ordonner :  \n",
    "> le mod√®le doit apprendre une **r√®gle de calcul** et **propager une retenue**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Formulation du probl√®me\n",
    "\n",
    "Entr√©e (source) : une cha√Æne du type  \n",
    "`\"123+45\"`  \n",
    "\n",
    "Sortie (cible) : la somme sous forme de cha√Æne  \n",
    "`\"168\"`\n",
    "\n",
    "On travaille **au niveau caract√®re** (char-level), ce qui permet :\n",
    "- un vocabulaire tr√®s petit (digits + symboles),\n",
    "- une visualisation claire des erreurs,\n",
    "- un apprentissage progressif.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Objectifs du TP\n",
    "\n",
    "√Ä la fin du TP, l‚Äô√©tudiant sera capable de :\n",
    "1. G√©n√©rer un dataset synth√©tique d‚Äôadditions.\n",
    "2. Construire un vocabulaire de caract√®res avec `PAD`, `SOS`, `EOS`.\n",
    "3. Impl√©menter un Seq2Seq LSTM (encodeur + d√©codeur).\n",
    "4. Entra√Æner avec teacher forcing.\n",
    "5. √âvaluer avec **exact match** (r√©sultat enti√®rement correct).\n",
    "6. √âtudier la g√©n√©ralisation en augmentant la longueur des nombres.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå D√©roulement du TP (plan)\n",
    "\n",
    "1. Param√®tres + vocabulaire\n",
    "2. G√©n√©ration des donn√©es (a+b)\n",
    "3. Dataset / DataLoader / padding\n",
    "4. Mod√®les : Encoder / Decoder / Seq2Seq\n",
    "5. Entra√Ænement + courbes\n",
    "6. Inference greedy + exemples\n",
    "7. Tests de g√©n√©ralisation (longueurs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62908f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d2b04",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1) Param√®tres du TP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Donn√©es ---\n",
    "MAX_DIGITS = 3          # a et b auront entre 1 et MAX_DIGITS chiffres\n",
    "TRAIN_SIZE = 12000\n",
    "VALID_SIZE = 1500\n",
    "TEST_SIZE  = 1500\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# --- Mod√®le ---\n",
    "EMBED_DIM  = 64\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 1\n",
    "DROPOUT    = 0.0\n",
    "\n",
    "EPOCHS = 15\n",
    "LR = 1e-3\n",
    "\n",
    "TEACHER_FORCING_RATIO = 0.7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828896d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2) Vocabulaire caract√®re par caract√®re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIALS = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
    "CHARS = list(\"0123456789+\")\n",
    "itos = SPECIALS + CHARS\n",
    "stoi = {ch:i for i,ch in enumerate(itos)}\n",
    "\n",
    "PAD = stoi[\"<PAD>\"]\n",
    "SOS = stoi[\"<SOS>\"]\n",
    "EOS = stoi[\"<EOS>\"]\n",
    "\n",
    "VOCAB_SIZE = len(itos)\n",
    "\n",
    "itos, VOCAB_SIZE, PAD, SOS, EOS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6f7e63",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3) G√©n√©ration des paires (source, cible)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_addition(max_digits=MAX_DIGITS):\n",
    "    a = random.randint(0, 10**max_digits - 1)\n",
    "    b = random.randint(0, 10**max_digits - 1)\n",
    "    src = f\"{a}+{b}\"\n",
    "    tgt = f\"{a+b}\"\n",
    "    return src, tgt\n",
    "\n",
    "for _ in range(5):\n",
    "    print(sample_addition())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d050c6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4) Encodage en ids + padding + DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871a4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_string(s):\n",
    "    return [stoi[ch] for ch in s]\n",
    "\n",
    "def pad_batch(seqs, pad_value=PAD):\n",
    "    max_len = max(len(s) for s in seqs)\n",
    "    out = []\n",
    "    lengths = []\n",
    "    for s in seqs:\n",
    "        lengths.append(len(s))\n",
    "        out.append(s + [pad_value]*(max_len - len(s)))\n",
    "    return torch.tensor(out, dtype=torch.long), torch.tensor(lengths, dtype=torch.long)\n",
    "\n",
    "class AdditionDataset(Dataset):\n",
    "    def __init__(self, n, max_digits=MAX_DIGITS):\n",
    "        self.samples = [sample_addition(max_digits) for _ in range(n)]\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_strs = [b[0] for b in batch]\n",
    "    tgt_strs = [b[1] for b in batch]\n",
    "\n",
    "    src_ids = [encode_string(s) for s in src_strs]\n",
    "    tgt_ids = [encode_string(s) for s in tgt_strs]\n",
    "\n",
    "    tgt_in_ids  = [[SOS] + t for t in tgt_ids]\n",
    "    tgt_out_ids = [t + [EOS] for t in tgt_ids]\n",
    "\n",
    "    src, src_len = pad_batch(src_ids, PAD)\n",
    "    tgt_in, _ = pad_batch(tgt_in_ids, PAD)\n",
    "    tgt_out, _ = pad_batch(tgt_out_ids, PAD)\n",
    "\n",
    "    return src, src_len, tgt_in, tgt_out\n",
    "\n",
    "train_ds = AdditionDataset(TRAIN_SIZE, MAX_DIGITS)\n",
    "valid_ds = AdditionDataset(VALID_SIZE, MAX_DIGITS)\n",
    "test_ds  = AdditionDataset(TEST_SIZE,  MAX_DIGITS)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "src, src_len, tgt_in, tgt_out = next(iter(train_loader))\n",
    "src.shape, tgt_in.shape, tgt_out.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd727a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5) Mod√®les : Encodeur / D√©codeur LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e35bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=1, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embed_dim, hidden_dim, num_layers=num_layers,\n",
    "            batch_first=True, dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "    def forward(self, src):\n",
    "        emb = self.embedding(src)\n",
    "        _, (h, c) = self.lstm(emb)\n",
    "        return h, c\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=1, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embed_dim, hidden_dim, num_layers=num_layers,\n",
    "            batch_first=True, dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        emb = self.embedding(x)\n",
    "        out, (h, c) = self.lstm(emb, (h, c))\n",
    "        logits = self.fc(out)\n",
    "        return logits, h, c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302a0dae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6) Seq2Seq + Teacher Forcing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5bb850",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, tgt_in, teacher_forcing_ratio=0.7):\n",
    "        B, Ttgt = tgt_in.shape\n",
    "        V = self.decoder.fc.out_features\n",
    "\n",
    "        h, c = self.encoder(src)\n",
    "\n",
    "        logits_all = torch.zeros(B, Ttgt, V, device=src.device)\n",
    "\n",
    "        input_tok = tgt_in[:, 0].unsqueeze(1)  # SOS\n",
    "\n",
    "        for t in range(Ttgt):\n",
    "            step_logits, h, c = self.decoder(input_tok, h, c)\n",
    "            logits_all[:, t:t+1, :] = step_logits\n",
    "\n",
    "            pred_tok = step_logits.argmax(-1)\n",
    "\n",
    "            if t + 1 < Ttgt:\n",
    "                use_tf = random.random() < teacher_forcing_ratio\n",
    "                input_tok = tgt_in[:, t+1].unsqueeze(1) if use_tf else pred_tok\n",
    "\n",
    "        return logits_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1963c4bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7) Loss + m√©triques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a9a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "def token_accuracy(logits, targets, pad_idx=PAD):\n",
    "    pred = logits.argmax(-1)\n",
    "    mask = targets != pad_idx\n",
    "    correct = (pred == targets) & mask\n",
    "    return correct.sum().item() / mask.sum().item()\n",
    "\n",
    "def exact_match(logits, targets, pad_idx=PAD):\n",
    "    pred = logits.argmax(-1).detach().cpu().numpy()\n",
    "    gold = targets.detach().cpu().numpy()\n",
    "    B = gold.shape[0]\n",
    "    ok = 0\n",
    "    for i in range(B):\n",
    "        g = [t for t in gold[i].tolist() if t != pad_idx]\n",
    "        p = [t for t in pred[i].tolist() if t != pad_idx]\n",
    "        ok += int(p == g)\n",
    "    return ok / B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fb92d9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8) Entra√Ænement / √âvaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, tf_ratio=0.7):\n",
    "    model.train()\n",
    "    total_loss, total_tokacc, total_em = 0.0, 0.0, 0.0\n",
    "\n",
    "    for src, src_len, tgt_in, tgt_out in loader:\n",
    "        src = src.to(device)\n",
    "        tgt_in = tgt_in.to(device)\n",
    "        tgt_out = tgt_out.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(src, tgt_in, teacher_forcing_ratio=tf_ratio)\n",
    "\n",
    "        B, T, V = logits.shape\n",
    "        loss = criterion(logits.reshape(B*T, V), tgt_out.reshape(B*T))\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_tokacc += token_accuracy(logits, tgt_out)\n",
    "        total_em += exact_match(logits, tgt_out)\n",
    "\n",
    "    n = len(loader)\n",
    "    return total_loss/n, total_tokacc/n, total_em/n\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_tokacc, total_em = 0.0, 0.0, 0.0\n",
    "\n",
    "    for src, src_len, tgt_in, tgt_out in loader:\n",
    "        src = src.to(device)\n",
    "        tgt_in = tgt_in.to(device)\n",
    "        tgt_out = tgt_out.to(device)\n",
    "\n",
    "        logits = model(src, tgt_in, teacher_forcing_ratio=0.0)\n",
    "\n",
    "        B, T, V = logits.shape\n",
    "        loss = criterion(logits.reshape(B*T, V), tgt_out.reshape(B*T))\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_tokacc += token_accuracy(logits, tgt_out)\n",
    "        total_em += exact_match(logits, tgt_out)\n",
    "\n",
    "    n = len(loader)\n",
    "    return total_loss/n, total_tokacc/n, total_em/n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc0d7cf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9) Lancement de l‚Äôentra√Ænement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b969366",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT)\n",
    "decoder = Decoder(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT)\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "hist = {\"tr_loss\":[], \"va_loss\":[], \"tr_em\":[], \"va_em\":[]}\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_tok, tr_em = train_one_epoch(model, train_loader, optimizer, criterion, tf_ratio=TEACHER_FORCING_RATIO)\n",
    "    va_loss, va_tok, va_em = evaluate(model, valid_loader, criterion)\n",
    "\n",
    "    hist[\"tr_loss\"].append(tr_loss); hist[\"va_loss\"].append(va_loss)\n",
    "    hist[\"tr_em\"].append(tr_em);     hist[\"va_em\"].append(va_em)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train loss {tr_loss:.4f} EM {tr_em:.3f} | \"\n",
    "          f\"valid loss {va_loss:.4f} EM {va_em:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937a1758",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10) Courbes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55017fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(hist[\"tr_loss\"], label=\"train loss\")\n",
    "plt.plot(hist[\"va_loss\"], label=\"valid loss\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.legend(); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hist[\"tr_em\"], label=\"train exact match\")\n",
    "plt.plot(hist[\"va_em\"], label=\"valid exact match\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"exact match\"); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7cf3d9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11) Inference greedy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d84a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_ids(ids):\n",
    "    out = []\n",
    "    for i in ids:\n",
    "        if i == PAD or i == SOS:\n",
    "            continue\n",
    "        if i == EOS:\n",
    "            break\n",
    "        out.append(itos[i])\n",
    "    return \"\".join(out)\n",
    "\n",
    "@torch.no_grad()\n",
    "def greedy_generate(model, src_str, max_len=12):\n",
    "    model.eval()\n",
    "    src_ids = torch.tensor([encode_string(src_str)], dtype=torch.long, device=device)\n",
    "    h, c = model.encoder(src_ids)\n",
    "\n",
    "    input_tok = torch.tensor([[SOS]], dtype=torch.long, device=device)\n",
    "    out_ids = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        logits, h, c = model.decoder(input_tok, h, c)\n",
    "        pred = logits.argmax(-1)\n",
    "        tok = pred.item()\n",
    "        out_ids.append(tok)\n",
    "        input_tok = pred\n",
    "        if tok == EOS:\n",
    "            break\n",
    "\n",
    "    return decode_ids(out_ids)\n",
    "\n",
    "for s in [\"3+7\", \"12+5\", \"99+1\", \"123+45\", \"7+250\"]:\n",
    "    print(s, \"=>\", greedy_generate(model, s, max_len=20), \"(gold:\", str(eval(s)), \")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8435ca8b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12) Test final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476179dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_tok, test_em = evaluate(model, test_loader, criterion)\n",
    "print(f\"TEST | loss {test_loss:.4f} exact match {test_em:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a88f1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 13) Analyse d‚Äôerreurs (qualitative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96135361",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = 0\n",
    "for i in range(400):\n",
    "    src, tgt = test_ds[i]\n",
    "    pred = greedy_generate(model, src, max_len=25)\n",
    "    if pred != tgt:\n",
    "        print(\"src :\", src)\n",
    "        print(\"pred:\", pred)\n",
    "        print(\"gold:\", tgt)\n",
    "        print(\"---\")\n",
    "        errors += 1\n",
    "        if errors >= 10:\n",
    "            break\n",
    "\n",
    "print(\"Errors shown:\", errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed420d5c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 14) Test de g√©n√©ralisation (MAX_DIGITS + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e042b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generalization_test(model, max_digits_test=MAX_DIGITS+1, n=300):\n",
    "    ok = 0\n",
    "    for _ in range(n):\n",
    "        src, tgt = sample_addition(max_digits=max_digits_test)\n",
    "        pred = greedy_generate(model, src, max_len=40)\n",
    "        ok += int(pred == tgt)\n",
    "    return ok / n\n",
    "\n",
    "gen_em = generalization_test(model, max_digits_test=MAX_DIGITS+1, n=300)\n",
    "print(f\"Generalization exact match (test digits={MAX_DIGITS+1}): {gen_em:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c58fb2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 15) Questions √† rendre (rapport 1‚Äì2 pages)\n",
    "\n",
    "1. Pourquoi l‚Äôaddition symbolique est-elle plus difficile que l‚Äôinversion ?  \n",
    "2. Expliquez le r√¥le de `SOS`, `EOS`, `PAD`.  \n",
    "3. Identifiez une erreur due √† la retenue et expliquez-la.  \n",
    "4. Comparez `TEACHER_FORCING_RATIO=0.0` vs `0.7` vs `0.9`.  \n",
    "5. Discutez la g√©n√©ralisation vers des nombres plus longs.  \n",
    "6. Proposez une am√©lioration : attention, transformer, ou inversion de la source.\n",
    "\n",
    "---\n",
    "\n",
    "## 16) Extensions (facultatif)\n",
    "\n",
    "- Inverser la source et comparer : aide-t-il la performance ?\n",
    "- Essayer GRU.\n",
    "- Ajouter attention (T3).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
