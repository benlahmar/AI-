{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adcf65ea",
   "metadata": {},
   "source": [
    "# TP NLP ‚Äî T2 : Encodeur‚ÄìD√©codeur **Bidirectionnel** (BiLSTM) ‚Äî Master IA\n",
    "\n",
    "Ce notebook correspond au **Tutoriel 2 (T2)** du module NLP.\n",
    "Il introduit un **encodeur bidirectionnel** (BiLSTM) afin d‚Äôam√©liorer le mod√®le Seq2Seq vu en T1.\n",
    "\n",
    "---\n",
    "## üéØ Objectifs p√©dagogiques\n",
    "- Comprendre les limites du Seq2Seq unidirectionnel\n",
    "- Expliquer le fonctionnement d‚Äôun **RNN bidirectionnel**\n",
    "- Impl√©menter un **encodeur BiLSTM + d√©codeur LSTM**\n",
    "- Comparer empiriquement avec le mod√®le T1\n",
    "- Pr√©parer conceptuellement le m√©canisme d‚Äô**attention** (T3)\n",
    "\n",
    "---\n",
    "## üß† Motivation\n",
    "Dans un encodeur classique, la s√©quence est lue de gauche √† droite.\n",
    "Les premiers tokens sont donc **moins bien repr√©sent√©s** dans l‚Äô√©tat final.\n",
    "\n",
    "Un **BiLSTM** lit la s√©quence :\n",
    "- une fois de gauche √† droite,\n",
    "- une fois de droite √† gauche,\n",
    "\n",
    "et concat√®ne les deux repr√©sentations.\n",
    "\n",
    "---\n",
    "## üß© Probl√®me √©tudi√©\n",
    "Nous reprenons le **probl√®me d‚Äôinversion de s√©quence** :\n",
    "```\n",
    "[1, 5, 7, 3] ‚Üí [3, 7, 5, 1]\n",
    "```\n",
    "Ce probl√®me permet d‚Äôobserver clairement le gain apport√© par la bidirectionnalit√©.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c6011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d09368",
   "metadata": {},
   "source": [
    "## 1) Param√®tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f70fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "V = 20\n",
    "MIN_LEN, MAX_LEN = 3, 12\n",
    "\n",
    "TRAIN_SIZE = 8000\n",
    "VALID_SIZE = 1000\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EMBED_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "EPOCHS = 10\n",
    "LR = 1e-3\n",
    "TEACHER_FORCING_RATIO = 0.7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c457a",
   "metadata": {},
   "source": [
    "## 2) Vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ac24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PAD = 0\n",
    "SOS = V + 1\n",
    "EOS = V + 2\n",
    "VOCAB_SIZE = V + 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1059adb",
   "metadata": {},
   "source": [
    "## 3) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1162fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_pair():\n",
    "    L = random.randint(MIN_LEN, MAX_LEN)\n",
    "    src = [random.randint(1, V) for _ in range(L)]\n",
    "    tgt = [SOS] + list(reversed(src)) + [EOS]\n",
    "    return src, tgt\n",
    "\n",
    "class ReverseDataset(Dataset):\n",
    "    def __init__(self, n):\n",
    "        self.data = [generate_pair() for _ in range(n)]\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self, i): return self.data[i]\n",
    "\n",
    "def pad(seqs):\n",
    "    m = max(len(s) for s in seqs)\n",
    "    return torch.tensor([s + [PAD]*(m-len(s)) for s in seqs])\n",
    "\n",
    "def collate(batch):\n",
    "    src = pad([b[0] for b in batch])\n",
    "    tgt = pad([b[1] for b in batch])\n",
    "    return src, tgt[:,:-1], tgt[:,1:]\n",
    "\n",
    "train_loader = DataLoader(ReverseDataset(TRAIN_SIZE), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate)\n",
    "valid_loader = DataLoader(ReverseDataset(VALID_SIZE), batch_size=BATCH_SIZE, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f05c3a5",
   "metadata": {},
   "source": [
    "## 4) Encodeur **Bidirectionnel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f99011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BiEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(VOCAB_SIZE, EMBED_DIM, padding_idx=PAD)\n",
    "        self.lstm = nn.LSTM(\n",
    "            EMBED_DIM, HIDDEN_DIM, batch_first=True, bidirectional=True\n",
    "        )\n",
    "        self.fc_h = nn.Linear(HIDDEN_DIM*2, HIDDEN_DIM)\n",
    "        self.fc_c = nn.Linear(HIDDEN_DIM*2, HIDDEN_DIM)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.emb(x)\n",
    "        _, (h, c) = self.lstm(emb)\n",
    "        h_cat = torch.cat([h[0], h[1]], dim=1)\n",
    "        c_cat = torch.cat([c[0], c[1]], dim=1)\n",
    "        h0 = torch.tanh(self.fc_h(h_cat)).unsqueeze(0)\n",
    "        c0 = torch.tanh(self.fc_c(c_cat)).unsqueeze(0)\n",
    "        return h0, c0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378b320f",
   "metadata": {},
   "source": [
    "## 5) D√©codeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f9fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(VOCAB_SIZE, EMBED_DIM, padding_idx=PAD)\n",
    "        self.lstm = nn.LSTM(EMBED_DIM, HIDDEN_DIM, batch_first=True)\n",
    "        self.fc = nn.Linear(HIDDEN_DIM, VOCAB_SIZE)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        emb = self.emb(x)\n",
    "        out, (h, c) = self.lstm(emb, (h, c))\n",
    "        return self.fc(out), h, c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65ec7d7",
   "metadata": {},
   "source": [
    "## 6) Seq2Seq bidirectionnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc9b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__()\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "\n",
    "    def forward(self, src, tgt_in, tf=0.7):\n",
    "        B, T = tgt_in.shape\n",
    "        V = VOCAB_SIZE\n",
    "        h, c = self.enc(src)\n",
    "        outputs = torch.zeros(B, T, V, device=src.device)\n",
    "\n",
    "        x = tgt_in[:,0].unsqueeze(1)\n",
    "        for t in range(T):\n",
    "            logits, h, c = self.dec(x, h, c)\n",
    "            outputs[:,t:t+1,:] = logits\n",
    "            pred = logits.argmax(-1)\n",
    "            if t+1 < T:\n",
    "                x = tgt_in[:,t+1].unsqueeze(1) if random.random()<tf else pred\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f18640",
   "metadata": {},
   "source": [
    "## 7) Entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9492f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Seq2Seq(BiEncoder(), Decoder()).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    total = 0\n",
    "    for src, tin, tout in loader:\n",
    "        src, tin, tout = src.to(device), tin.to(device), tout.to(device)\n",
    "        if train: optimizer.zero_grad()\n",
    "        logits = model(src, tin, TEACHER_FORCING_RATIO if train else 0.0)\n",
    "        B,T,V = logits.shape\n",
    "        loss = criterion(logits.view(B*T, V), tout.view(B*T))\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        total += loss.item()\n",
    "    return total/len(loader)\n",
    "\n",
    "for e in range(1, EPOCHS+1):\n",
    "    tr = run_epoch(train_loader, True)\n",
    "    va = run_epoch(valid_loader, False)\n",
    "    print(f\"Epoch {e:02d} | train {tr:.4f} | valid {va:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf03e1ad",
   "metadata": {},
   "source": [
    "---\n",
    "## 8) Analyse p√©dagogique\n",
    "\n",
    "### Ce que montre ce TP\n",
    "- Le BiLSTM encode mieux les **d√©pendances longues**\n",
    "- Les premiers tokens sont mieux restitu√©s\n",
    "- Le goulot d‚Äô√©tranglement subsiste\n",
    "\n",
    "üëâ Prochaine question naturelle :\n",
    "**Pourquoi ne pas laisser le d√©codeur acc√©der √† tous les √©tats de l‚Äôencodeur ?**\n",
    "\n",
    "‚û°Ô∏è R√©ponse : **Attention (T3)**.\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
