{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a297c2",
   "metadata": {},
   "source": [
    "# TP NLP ‚Äî T5 : **Transformer Encodeur‚ÄìD√©codeur Complet** (from scratch) ‚Äî Master IA\n",
    "\n",
    "Ce notebook correspond au **TUTORIEL 5 (T5)**.\n",
    "Apr√®s :\n",
    "- T1 : Seq2Seq RNN\n",
    "- T2 : Encodeur bidirectionnel\n",
    "- T3 : Attention (Bahdanau)\n",
    "- T4 : Transformer *encoder-only*\n",
    "\n",
    "üëâ Nous impl√©mentons maintenant un **Transformer complet Encodeur‚ÄìD√©codeur**,  \n",
    "architecture utilis√©e par **Transformer original**, **T5**, **BART**, **Marian**, etc.\n",
    "\n",
    "---\n",
    "## üéØ Objectifs p√©dagogiques\n",
    "\n",
    "√Ä la fin de ce TP, l‚Äô√©tudiant saura :\n",
    "- expliquer la diff√©rence **encoder-only / decoder-only / encoder‚Äìdecoder**,\n",
    "- comprendre la **self-attention masqu√©e** c√¥t√© d√©codeur,\n",
    "- impl√©menter :\n",
    "  - un encodeur Transformer,\n",
    "  - un d√©codeur Transformer,\n",
    "  - l‚Äôattention **encodeur‚Äìd√©codeur** (cross-attention),\n",
    "- entra√Æner un Transformer Seq2Seq sur un probl√®me jouet,\n",
    "- faire le lien avec la **traduction automatique**.\n",
    "\n",
    "‚ö†Ô∏è Objectif p√©dagogique : **architecture claire**, pas performance maximale.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e6450c",
   "metadata": {},
   "source": [
    "\n",
    "## üß† Rappel conceptuel : pourquoi un encodeur‚Äìd√©codeur ?\n",
    "\n",
    "Certaines t√¢ches n√©cessitent :\n",
    "- une **s√©quence source** enti√®rement disponible,\n",
    "- une **s√©quence cible g√©n√©r√©e pas √† pas**.\n",
    "\n",
    "Exemples :\n",
    "- Traduction\n",
    "- R√©sum√©\n",
    "- Question‚ÄìR√©ponse g√©n√©ratif\n",
    "\n",
    "üëâ L‚Äôencodeur :\n",
    "- lit toute la source,\n",
    "- produit une m√©moire contextuelle.\n",
    "\n",
    "üëâ Le d√©codeur :\n",
    "- g√©n√®re token par token,\n",
    "- regarde :\n",
    "  - son pass√© (self-attention masqu√©e),\n",
    "  - la source (cross-attention).\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52afaf",
   "metadata": {},
   "source": [
    "\n",
    "## üß© Probl√®me p√©dagogique choisi\n",
    "\n",
    "On reste sur un probl√®me **simple et contr√¥l√©** :\n",
    "### üëâ Inversion de s√©quence (version Seq2Seq)\n",
    "\n",
    "Source :\n",
    "```\n",
    "[1, 5, 7, 3]\n",
    "```\n",
    "Cible :\n",
    "```\n",
    "[3, 7, 5, 1]\n",
    "```\n",
    "\n",
    "Pourquoi encore ce probl√®me ?\n",
    "- pas de complexit√© linguistique,\n",
    "- permet de visualiser **self-attention** et **cross-attention**,\n",
    "- comparaison directe avec T1‚ÄìT4.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a28988",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1590f49d",
   "metadata": {},
   "source": [
    "## 1) Param√®tres et vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caace3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "V = 20\n",
    "MIN_LEN, MAX_LEN = 3, 12\n",
    "\n",
    "TRAIN_SIZE = 8000\n",
    "VALID_SIZE = 1000\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "D_MODEL = 128\n",
    "N_HEADS = 4\n",
    "FF_DIM = 256\n",
    "\n",
    "EPOCHS = 10\n",
    "LR = 1e-3\n",
    "\n",
    "PAD = 0\n",
    "SOS = V + 1\n",
    "EOS = V + 2\n",
    "VOCAB_SIZE = V + 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d373134f",
   "metadata": {},
   "source": [
    "## 2) Dataset Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_pair():\n",
    "    L = random.randint(MIN_LEN, MAX_LEN)\n",
    "    src = [random.randint(1, V) for _ in range(L)]\n",
    "    tgt = [SOS] + list(reversed(src)) + [EOS]\n",
    "    return src, tgt\n",
    "\n",
    "class ReverseDataset(Dataset):\n",
    "    def __init__(self, n):\n",
    "        self.data = [generate_pair() for _ in range(n)]\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self, i): return self.data[i]\n",
    "\n",
    "def pad(seqs):\n",
    "    m = max(len(s) for s in seqs)\n",
    "    return torch.tensor([s+[PAD]*(m-len(s)) for s in seqs], dtype=torch.long)\n",
    "\n",
    "def collate(batch):\n",
    "    src = pad([b[0] for b in batch])\n",
    "    tgt = pad([b[1] for b in batch])\n",
    "    return src, tgt[:,:-1], tgt[:,1:]\n",
    "\n",
    "train_loader = DataLoader(ReverseDataset(TRAIN_SIZE), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate)\n",
    "valid_loader = DataLoader(ReverseDataset(VALID_SIZE), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12edf77",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Positional Encoding\n",
    "Identique √† T4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=100):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e7e72a",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Attention de base (scaled dot-product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ScaledDotAttention(nn.Module):\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        d_k = Q.size(-1)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        return torch.matmul(attn, V), attn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91f236",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Multi-Head Attention (r√©utilisable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        self.d_k = d_model // n_heads\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.Wq = nn.Linear(d_model, d_model)\n",
    "        self.Wk = nn.Linear(d_model, d_model)\n",
    "        self.Wv = nn.Linear(d_model, d_model)\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        self.attn = ScaledDotAttention()\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        B, Tq, D = Q.shape\n",
    "        Tk = K.size(1)\n",
    "\n",
    "        Q = self.Wq(Q).view(B, Tq, self.n_heads, self.d_k).transpose(1,2)\n",
    "        K = self.Wk(K).view(B, Tk, self.n_heads, self.d_k).transpose(1,2)\n",
    "        V = self.Wv(V).view(B, Tk, self.n_heads, self.d_k).transpose(1,2)\n",
    "\n",
    "        out, attn = self.attn(Q, K, V, mask)\n",
    "        out = out.transpose(1,2).contiguous().view(B, Tq, D)\n",
    "        return self.fc(out), attn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9094b32",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Feed-Forward + Bloc Encodeur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e86e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, ff_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, d_model)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(D_MODEL, N_HEADS)\n",
    "        self.ff = FeedForward(D_MODEL, FF_DIM)\n",
    "        self.norm1 = nn.LayerNorm(D_MODEL)\n",
    "        self.norm2 = nn.LayerNorm(D_MODEL)\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        attn_out,_ = self.attn(x, x, x, src_mask)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        ff_out = self.ff(x)\n",
    "        x = self.norm2(x + ff_out)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0833de7b",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Bloc D√©codeur Transformer\n",
    "\n",
    "Contient **deux attentions** :\n",
    "1. Self-attention **masqu√©e** (ne regarde pas le futur)\n",
    "2. Attention encodeur‚Äìd√©codeur (cross-attention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c719dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def subsequent_mask(size):\n",
    "    mask = torch.tril(torch.ones(size, size)).unsqueeze(0)\n",
    "    return mask\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(D_MODEL, N_HEADS)\n",
    "        self.cross_attn = MultiHeadAttention(D_MODEL, N_HEADS)\n",
    "        self.ff = FeedForward(D_MODEL, FF_DIM)\n",
    "        self.norm1 = nn.LayerNorm(D_MODEL)\n",
    "        self.norm2 = nn.LayerNorm(D_MODEL)\n",
    "        self.norm3 = nn.LayerNorm(D_MODEL)\n",
    "\n",
    "    def forward(self, x, memory, tgt_mask, src_mask):\n",
    "        attn1,_ = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + attn1)\n",
    "\n",
    "        attn2,_ = self.cross_attn(x, memory, memory, src_mask)\n",
    "        x = self.norm2(x + attn2)\n",
    "\n",
    "        ff_out = self.ff(x)\n",
    "        x = self.norm3(x + ff_out)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e330f3eb",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Transformer Encodeur‚ÄìD√©codeur complet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e64ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerSeq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(VOCAB_SIZE, D_MODEL, padding_idx=PAD)\n",
    "        self.pe = PositionalEncoding(D_MODEL)\n",
    "        self.encoder = EncoderBlock()\n",
    "        self.decoder = DecoderBlock()\n",
    "        self.fc = nn.Linear(D_MODEL, VOCAB_SIZE)\n",
    "\n",
    "    def forward(self, src, tgt_in):\n",
    "        src_mask = (src != PAD).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = subsequent_mask(tgt_in.size(1)).to(tgt_in.device)\n",
    "\n",
    "        src_emb = self.pe(self.emb(src))\n",
    "        memory = self.encoder(src_emb, src_mask)\n",
    "\n",
    "        tgt_emb = self.pe(self.emb(tgt_in))\n",
    "        dec_out = self.decoder(tgt_emb, memory, tgt_mask, src_mask)\n",
    "\n",
    "        return self.fc(dec_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023fe779",
   "metadata": {},
   "source": [
    "## 9) Entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2624807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = TransformerSeq2Seq().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    total = 0\n",
    "    for src, tgt_in, tgt_out in loader:\n",
    "        src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "        logits = model(src, tgt_in)\n",
    "        B,T,V = logits.shape\n",
    "        loss = criterion(logits.view(B*T, V), tgt_out.view(B*T))\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        total += loss.item()\n",
    "    return total/len(loader)\n",
    "\n",
    "for e in range(1, EPOCHS+1):\n",
    "    tr = run_epoch(train_loader, True)\n",
    "    va = run_epoch(valid_loader, False)\n",
    "    print(f\"Epoch {e:02d} | train {tr:.4f} | valid {va:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b667a",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Conclusion p√©dagogique\n",
    "\n",
    "### Ce que les √©tudiants doivent retenir :\n",
    "- Le d√©codeur **voit son pass√©**, mais pas son futur\n",
    "- Le d√©codeur **voit la source** via la cross-attention\n",
    "- L‚Äôencodeur‚Äìd√©codeur est la base de la traduction automatique\n",
    "- GPT = d√©codeur seul\n",
    "- BERT = encodeur seul\n",
    "\n",
    "üëâ √Ä partir d‚Äôici, on comprend toute la famille des LLM.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
